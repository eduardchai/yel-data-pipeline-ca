{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Set google service account\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/eduardchai/Workspace/NUS/eb5001-big-data-for-analytics/CA/big-data-ca-svc-acc.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure spark config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.project.id\", \"big-data-project-272506\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "sc._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\", \"/Users/eduardchai/Workspace/NUS/eb5001-big-data-for-analytics/CA/big-data-ca-svc-acc.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config(conf=sc.getConf())\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from bigquery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x12040a550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently this only supports queries which have at least 10 MB of results\n",
    "QUERY = \"SELECT * FROM `big-data-project-272506.mock.restaurant_reviews_raw` WHERE DATE(timestamp) = '2020-04-04'\"\n",
    "bq = bigquery.Client()\n",
    "query_job = bq.query(QUERY)\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "        .format(\"bigquery\")\\\n",
    "        .option(\"dataset\", query_job.destination.dataset_id)\\\n",
    "        .option(\"table\", query_job.destination.table_id)\\\n",
    "        .load()\\\n",
    "        .persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    new_words = []\n",
    "    stop = stopwords.words('english')\n",
    "    try:\n",
    "        for word in words.split():\n",
    "            if word not in stop:\n",
    "                new_words.append(word)\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_content(sentence):\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sentence = ' '.join(word for word in tokenizer.tokenize(sentence))\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_length(review):\n",
    "    return int(len(review.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rating_deviation(user_rating, restaurant_rating):\n",
    "    return float(abs(float(user_rating) - float(restaurant_rating)) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reviews):\n",
    "    import numpy as np\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    \n",
    "    vector = TfidfVectorizer(min_df=0)\n",
    "    max = 0\n",
    "    try:\n",
    "        tfidf = vector.fit_transform(reviews)\n",
    "        cosine = 1 - pairwise_distances(tfidf, metric='cosine')\n",
    "        np.fill_diagonal(cosine, -np.inf)\n",
    "        max = cosine.max()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return float(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_udf = udf(remove_stopwords)\n",
    "preprocess_content_udf = udf(preprocess_content)\n",
    "compute_content_length_udf = udf(compute_content_length, IntegerType())\n",
    "compute_rating_deviation_udf = udf(compute_rating_deviation, FloatType())\n",
    "compute_cosine_similarity_udf = udf(compute_cosine_similarity, FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df.withColumn(\"review_content\", remove_stopwords_udf(\"review_content\"))\n",
    "df_processed = df_processed.withColumn(\"review_content\", preprocess_content_udf(\"review_content\"))\n",
    "df_processed = df_processed.withColumn(\"review_length\", compute_content_length_udf(\"review_content\"))\n",
    "df_processed = df_processed.withColumn(\"rating_deviation\", compute_rating_deviation_udf(\"rating\", \"restaurant_rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute maximum number of review per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_count = df_processed.groupby('reviewer_id', 'timestamp').count().groupby().max().collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_review_per_user_df = df_processed.groupby('reviewer_id', 'timestamp').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.join(\n",
    "    maximum_review_per_user_df, \n",
    "    (df_processed.reviewer_id == maximum_review_per_user_df.reviewer_id) & (df_processed.timestamp == maximum_review_per_user_df.timestamp)\n",
    ").select(df_processed[\"*\"], maximum_review_per_user_df[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnr_udf = udf(lambda x: x / max_review_count, FloatType())\n",
    "df_processed = df_processed.withColumn(\"maximum_review_per_user\", mnr_udf(\"count\"))\n",
    "df_processed = df_processed.drop(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.limit(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_df = df_processed.select(\"reviewer_id\", \"review_content\").rdd.reduceByKey(lambda a, b: a.append(b) if type(a) == list else ([a] + [b])).map(lambda x: (x[0], compute_cosine_similarity(x[1]))).toDF([\"reviewer_id\", \"cos_sim\"])\n",
    "# cos_sim_df = cos_sim_df.withColumn(\"cos_sim\", compute_cosine_similarity_udf(\"review_content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.join(cos_sim_df, df_processed.reviewer_id == cos_sim_df.reviewer_id).select(df_processed[\"*\"], cos_sim_df[\"cos_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.repartition(4).write\\\n",
    "  .format(\"bigquery\")\\\n",
    "  .mode(\"Overwrite\")\\\n",
    "  .option(\"table\",\"big-data-project-272506:yelp_dataset.restaurant_reviews_final\")\\\n",
    "  .option(\"temporaryGcsBucket\",\"big-data-project-272506-temp\")\\\n",
    "  .option(\"createDisposition\", \"CREATE_NEVER\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.filter(\"timestamp < '2014-04-05 00:00:00'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-ca",
   "language": "python",
   "name": "big-data-ca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
